{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question 1\n",
    "#Convolution layers within CNN could provide a high-dimension features, \n",
    "#while a fully connected layer offers a cheap way to learn the features from convolution layers. \n",
    "#Fully connected layers could improve the ability of expressing the non-linearity of learning tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question 2\n",
    "#It is known that both convolution kernels and pooling kernel do the regional works for data. \n",
    "#A convolution kernel is more likely to find out the pattern hidden in regions and then create a \n",
    "#-feature map that have the same size as input data. \n",
    "#While a pooling kernel always takes output from a convolution layer as input. \n",
    "#Pooling kernels could not only ‘summary’ the regional information, but also reduce the data size, \n",
    "#-which reduce the number of features(parameters) but not lose information of data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question3\n",
    "#A local response normalization layer is needed when one or more certain input of a convolution layer \n",
    "#-extremely larger than other inputs. \n",
    "#Since the large input would subdue other input. \n",
    "#For example, there are 5 inputs for a tanh activation function.\n",
    "#4 of the inputs are smaller than 1, and the other one is 2. \n",
    "#Consequently, the other four inputs have no effect to this tanh activation since when summary of inputs larger than 1, \n",
    "#-this function becomes saturated and constantly be 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().magic(u'matplotlib inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train original shape', (60000, 28, 28))\n",
      "('y_train original shape', (60000,))\n",
      "('X_test original shape', (10000, 28, 28))\n",
      "('y_test original shape', (10000,))\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"X_train original shape\", X_train.shape)\n",
    "print(\"y_train original shape\", y_train.shape)\n",
    "print(\"X_test original shape\", X_test.shape)\n",
    "print(\"y_test original shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x12699b190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOfxmmXL4zTL1/5EqC993WNdjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123bee650>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.title('Class '+ str(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_classes = 10\n",
    "#Converts a class integer to binary matrix(one-hot)\n",
    "Y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
    "#Example of to-categorical()\n",
    "y_train[0], Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Layer 1 \n",
    "#Parameter: 3x3 kernel size and 32 kernels\n",
    "#stride is defaulted to be 1\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Layer 2\n",
    "#Parameter: 3x3 kernel size, 32 kernels, 2x2 pooling\n",
    "#Batch normalization layer, axis is a integer denote the axis or features that should be normalized\n",
    "BatchNormalization(axis=-1)\n",
    "#stride is defaulted to be 1\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Layer 3\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64,(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "#Layer 4\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "# Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BatchNormalization()\n",
    "# dense implement: output = activation(dot(input, kernel) + bias) \n",
    "# after first layer, you don't need to specify the size of the input anymore\n",
    "model.add(Dense(512))#or model.add(Dense(512),activation='relu')\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization()\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "\n",
    "# model.add(Convolution2D(10,3,3, border_mode='same'))\n",
    "# model.add(GlobalAveragePooling2D())\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 594,922\n",
      "Trainable params: 594,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "height_shift_range=0.08, zoom_range=0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = gen.flow(X_train, Y_train, batch_size=64)\n",
    "test_generator = test_gen.flow(X_test, Y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bingyangwen/anaconda2/envs/tensorflow/lib/python2.7/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 116s - loss: 0.1664 - acc: 0.9482 - val_loss: 0.0367 - val_acc: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x136172110>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=128, nb_epoch=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s     \n",
      "()\n",
      "('Test accuracy: ', 0.98880000000000001)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "print()\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9952/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "\n",
    "predictions = list(predictions)\n",
    "actuals = list(y_test)\n",
    "\n",
    "sub = pd.DataFrame({'Actual': actuals, 'Predictions': predictions})\n",
    "sub.to_csv('./output_cnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "16384/29515 [===============>..............] - ETA: 0sDownloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26411008/26421880 [============================>.] - ETA: 0sDownloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "10296/5148 [============================================================] - 0s\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4415488/4422102 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# using fashion_Mnist\n",
    "from keras.datasets import fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train original shape', (60000, 28, 28))\n",
      "('y_train original shape', (60000,))\n",
      "('X_test original shape', (10000, 28, 28))\n",
      "('y_test original shape', (10000,))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x13674f610>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1363a2c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"X_train original shape\", X_train.shape)\n",
    "print(\"y_train original shape\", y_train.shape)\n",
    "print(\"X_test original shape\", X_test.shape)\n",
    "print(\"y_test original shape\", y_test.shape)\n",
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.title('Class '+ str(y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_classes = 10\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
    "\n",
    "y_train[0], Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 118s - loss: 0.4989 - acc: 0.8178 - val_loss: 0.3657 - val_acc: 0.8701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10ec5f990>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the model is same as the previous one \n",
    "train_generator = gen.flow(X_train, Y_train, batch_size=64)\n",
    "test_generator = test_gen.flow(X_test, Y_test, batch_size=64)\n",
    "model.fit(X_train, Y_train, batch_size=128, nb_epoch=1, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "937/937 [==============================] - 142s - loss: 0.4654 - acc: 0.8258 - val_loss: 0.3630 - val_acc: 0.8640\n",
      "Epoch 2/5\n",
      "937/937 [==============================] - 156s - loss: 0.3780 - acc: 0.8604 - val_loss: 0.3037 - val_acc: 0.8870\n",
      "Epoch 3/5\n",
      "937/937 [==============================] - 140s - loss: 0.3476 - acc: 0.8707 - val_loss: 0.2768 - val_acc: 0.9029\n",
      "Epoch 4/5\n",
      "937/937 [==============================] - 139s - loss: 0.3259 - acc: 0.8776 - val_loss: 0.2613 - val_acc: 0.9018\n",
      "Epoch 5/5\n",
      "937/937 [==============================] - 133s - loss: 0.3108 - acc: 0.8841 - val_loss: 0.2686 - val_acc: 0.9015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1364f1c90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=5, \n",
    " validation_data=test_generator, validation_steps=10000//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s     \n",
      "()\n",
      "('Test accuracy: ', 0.90349999999999997)\n"
     ]
    }
   ],
   "source": [
    "# accuracy for fashion_mnist\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print()\n",
    "print('Test accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test)\n",
    "\n",
    "predictions = list(predictions)\n",
    "actuals = list(y_test)\n",
    "\n",
    "sub = pd.DataFrame({'Actual': actuals, 'Predictions': predictions})\n",
    "sub.to_csv('./output_cnn.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
