{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the size of our encoded representations\n",
    "encoding_dim = 700  \n",
    "# 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(1000,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(1000, activation='sigmoid')(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)\n",
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(encoding_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Norm_Uni_Ex.py return a dataset that sampled from Normal, uniform and exponential distribution\n",
    "import distribution\n",
    "dataset = distribution.dataset(Normalization = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 1000)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24000 samples, validate on 6000 samples\n",
      "Epoch 1/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.6878 - val_loss: 0.6787\n",
      "Epoch 2/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.6704 - val_loss: 0.6618ss: 0.6\n",
      "Epoch 3/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.6521 - val_loss: 0.6421\n",
      "Epoch 4/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.6301 - val_loss: 0.6172\n",
      "Epoch 5/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.6005 - val_loss: 0.5818\n",
      "Epoch 6/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.5623 - val_loss: 0.5447\n",
      "Epoch 7/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.5315 - val_loss: 0.5199\n",
      "Epoch 8/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.5137 - val_loss: 0.5083ss:  - ETA: 0s -\n",
      "Epoch 9/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.5058 - val_loss: 0.5032\n",
      "Epoch 10/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.5027 - val_loss: 0.5015\n",
      "Epoch 11/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.5015 - val_loss: 0.5007\n",
      "Epoch 12/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.5012 - val_loss: 0.5004\n",
      "Epoch 13/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.5008 - val_loss: 0.5003\n",
      "Epoch 14/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.5007 - val_loss: 0.5004 - ETA:\n",
      "Epoch 15/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.5005 - val_loss: 0.5000\n",
      "Epoch 16/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.5005 - val_loss: 0.4999oss: 0.5\n",
      "Epoch 17/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.5002 - val_loss: 0.4997\n",
      "Epoch 18/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.5001 - val_loss: 0.4997\n",
      "Epoch 19/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4999 - val_loss: 0.4998\n",
      "Epoch 20/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4999 - val_loss: 0.4994\n",
      "Epoch 21/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4997 - val_loss: 0.4992\n",
      "Epoch 22/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4996 - val_loss: 0.4991\n",
      "Epoch 23/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4995 - val_loss: 0.4990\n",
      "Epoch 24/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4995 - val_loss: 0.4989\n",
      "Epoch 25/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4992 - val_loss: 0.4997\n",
      "Epoch 26/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4991 - val_loss: 0.4986\n",
      "Epoch 27/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4992 - val_loss: 0.4986\n",
      "Epoch 28/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4989 - val_loss: 0.4987\n",
      "Epoch 29/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4989 - val_loss: 0.4984\n",
      "Epoch 30/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4987 - val_loss: 0.4984\n",
      "Epoch 31/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4986 - val_loss: 0.4981\n",
      "Epoch 32/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4985 - val_loss: 0.4981\n",
      "Epoch 33/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4984 - val_loss: 0.4979\n",
      "Epoch 34/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4982 - val_loss: 0.4978\n",
      "Epoch 35/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4982 - val_loss: 0.4977\n",
      "Epoch 36/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4980 - val_loss: 0.4977\n",
      "Epoch 37/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4979 - val_loss: 0.4974\n",
      "Epoch 38/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4977 - val_loss: 0.4976\n",
      "Epoch 39/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4977 - val_loss: 0.4973\n",
      "Epoch 40/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4977 - val_loss: 0.4973\n",
      "Epoch 41/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4974 - val_loss: 0.4970\n",
      "Epoch 42/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4973 - val_loss: 0.4975\n",
      "Epoch 43/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4972 - val_loss: 0.4973\n",
      "Epoch 44/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4974 - val_loss: 0.4967\n",
      "Epoch 45/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4971 - val_loss: 0.4969\n",
      "Epoch 46/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4968 - val_loss: 0.4964\n",
      "Epoch 47/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4968 - val_loss: 0.4973\n",
      "Epoch 48/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4966 - val_loss: 0.4976\n",
      "Epoch 49/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4968 - val_loss: 0.4961\n",
      "Epoch 50/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4965 - val_loss: 0.4961\n",
      "Epoch 51/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4964 - val_loss: 0.4959\n",
      "Epoch 52/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4963 - val_loss: 0.4962\n",
      "Epoch 53/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4961 - val_loss: 0.4979\n",
      "Epoch 54/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4963 - val_loss: 0.4958\n",
      "Epoch 55/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4960 - val_loss: 0.4962\n",
      "Epoch 56/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4960 - val_loss: 0.4956\n",
      "Epoch 57/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4954 - val_loss: 0.4952\n",
      "Epoch 58/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4957 - val_loss: 0.4959\n",
      "Epoch 59/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4954 - val_loss: 0.4962\n",
      "Epoch 60/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4956 - val_loss: 0.4950\n",
      "Epoch 61/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4952 - val_loss: 0.4960\n",
      "Epoch 62/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4954 - val_loss: 0.4959\n",
      "Epoch 63/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4953 - val_loss: 0.4976\n",
      "Epoch 64/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4949 - val_loss: 0.4947\n",
      "Epoch 65/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4951 - val_loss: 0.4948\n",
      "Epoch 66/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4950 - val_loss: 0.4967\n",
      "Epoch 67/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4945 - val_loss: 0.4944\n",
      "Epoch 68/500\n",
      "24000/24000 [==============================] - 9s - loss: 0.4946 - val_loss: 0.4955\n",
      "Epoch 69/500\n",
      "24000/24000 [==============================] - 8s - loss: 0.4948 - val_loss: 0.4940\n",
      "Epoch 70/500\n",
      "24000/24000 [==============================] - 8s - loss: 0.4944 - val_loss: 0.4938\n",
      "Epoch 71/500\n",
      "24000/24000 [==============================] - 8s - loss: 0.4938 - val_loss: 0.4936\n",
      "Epoch 72/500\n",
      "24000/24000 [==============================] - 8s - loss: 0.4942 - val_loss: 0.4935\n",
      "Epoch 73/500\n",
      "24000/24000 [==============================] - 8s - loss: 0.4940 - val_loss: 0.4950\n",
      "Epoch 74/500\n",
      "24000/24000 [==============================] - 8s - loss: 0.4940 - val_loss: 0.4932\n",
      "Epoch 75/500\n",
      "24000/24000 [==============================] - 8s - loss: 0.4937 - val_loss: 0.4935\n",
      "Epoch 76/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4940 - val_loss: 0.4937\n",
      "Epoch 77/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4932 - val_loss: 0.4935\n",
      "Epoch 78/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4936 - val_loss: 0.4933\n",
      "Epoch 79/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4933 - val_loss: 0.4937\n",
      "Epoch 80/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4931 - val_loss: 0.4925\n",
      "Epoch 81/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4931 - val_loss: 0.4924\n",
      "Epoch 82/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4931 - val_loss: 0.4930\n",
      "Epoch 83/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4923 - val_loss: 0.4934\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 6s - loss: 0.4930 - val_loss: 0.4924\n",
      "Epoch 85/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4925 - val_loss: 0.4932\n",
      "Epoch 86/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4927 - val_loss: 0.4922\n",
      "Epoch 87/500\n",
      "24000/24000 [==============================] - 8s - loss: 0.4923 - val_loss: 0.4948\n",
      "Epoch 88/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4924 - val_loss: 0.4934\n",
      "Epoch 89/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4918 - val_loss: 0.4915\n",
      "Epoch 90/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4921 - val_loss: 0.4926\n",
      "Epoch 91/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4920 - val_loss: 0.4918\n",
      "Epoch 92/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4922 - val_loss: 0.4927ss: 0\n",
      "Epoch 93/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4919 - val_loss: 0.4922\n",
      "Epoch 94/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4916 - val_loss: 0.4919ss:\n",
      "Epoch 95/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4917 - val_loss: 0.4918\n",
      "Epoch 96/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4916 - val_loss: 0.4908\n",
      "Epoch 97/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4913 - val_loss: 0.4909\n",
      "Epoch 98/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4913 - val_loss: 0.4910\n",
      "Epoch 99/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4912 - val_loss: 0.4909\n",
      "Epoch 100/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4906 - val_loss: 0.4907\n",
      "Epoch 101/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4907 - val_loss: 0.4908\n",
      "Epoch 102/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4910 - val_loss: 0.4902\n",
      "Epoch 103/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4904 - val_loss: 0.4901\n",
      "Epoch 104/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4901 - val_loss: 0.4906\n",
      "Epoch 105/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4907 - val_loss: 0.4914\n",
      "Epoch 106/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4903 - val_loss: 0.4896\n",
      "Epoch 107/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4903 - val_loss: 0.4896\n",
      "Epoch 108/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4895 - val_loss: 0.4900\n",
      "Epoch 109/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4901 - val_loss: 0.4896\n",
      "Epoch 110/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4898 - val_loss: 0.4895\n",
      "Epoch 111/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4898 - val_loss: 0.4916\n",
      "Epoch 112/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4894 - val_loss: 0.4890\n",
      "Epoch 113/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4894 - val_loss: 0.4889\n",
      "Epoch 114/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4892 - val_loss: 0.4889\n",
      "Epoch 115/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4893 - val_loss: 0.4889\n",
      "Epoch 116/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4885 - val_loss: 0.4897\n",
      "Epoch 117/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4892 - val_loss: 0.4903\n",
      "Epoch 118/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4888 - val_loss: 0.4895\n",
      "Epoch 119/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4887 - val_loss: 0.4890\n",
      "Epoch 120/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4889 - val_loss: 0.4881\n",
      "Epoch 121/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4883 - val_loss: 0.4893\n",
      "Epoch 122/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4884 - val_loss: 0.4880\n",
      "Epoch 123/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4883 - val_loss: 0.4897\n",
      "Epoch 124/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4885 - val_loss: 0.4889\n",
      "Epoch 125/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4878 - val_loss: 0.4881\n",
      "Epoch 126/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4875 - val_loss: 0.4877ss: 0.48\n",
      "Epoch 127/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4879 - val_loss: 0.4876\n",
      "Epoch 128/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4878 - val_loss: 0.4882: \n",
      "Epoch 129/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4878 - val_loss: 0.4875ss: 0.4\n",
      "Epoch 130/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4878 - val_loss: 0.4871ss: 0\n",
      "Epoch 131/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4870 - val_loss: 0.4875\n",
      "Epoch 132/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4875 - val_loss: 0.4884\n",
      "Epoch 133/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4872 - val_loss: 0.4870\n",
      "Epoch 134/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4867 - val_loss: 0.4866\n",
      "Epoch 135/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4867 - val_loss: 0.4866\n",
      "Epoch 136/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4863 - val_loss: 0.4865\n",
      "Epoch 137/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4872 - val_loss: 0.4868\n",
      "Epoch 138/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4864 - val_loss: 0.4863\n",
      "Epoch 139/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4859 - val_loss: 0.4878\n",
      "Epoch 140/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4865 - val_loss: 0.4860\n",
      "Epoch 141/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4856 - val_loss: 0.4864\n",
      "Epoch 142/500\n",
      "24000/24000 [==============================] - 8s - loss: 0.4866 - val_loss: 0.4858\n",
      "Epoch 143/500\n",
      "24000/24000 [==============================] - 8s - loss: 0.4857 - val_loss: 0.4857\n",
      "Epoch 144/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4853 - val_loss: 0.4859\n",
      "Epoch 145/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4858 - val_loss: 0.4855\n",
      "Epoch 146/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4850 - val_loss: 0.4854ss - E - ETA: 0s - \n",
      "Epoch 147/500\n",
      "24000/24000 [==============================] - 6s - loss: 0.4851 - val_loss: 0.4853\n",
      "Epoch 148/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4848 - val_loss: 0.4853\n",
      "Epoch 149/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4849 - val_loss: 0.4854\n",
      "Epoch 150/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4854 - val_loss: 0.4862\n",
      "Epoch 151/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4849 - val_loss: 0.4849\n",
      "Epoch 152/500\n",
      "24000/24000 [==============================] - 7s - loss: 0.4852 - val_loss: 0.4849\n",
      "Epoch 153/500\n",
      " 7680/24000 [========>.....................] - ETA: 4s - loss: 0.4853"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-f472c52df1d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/bingyangwen/anaconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bingyangwen/anaconda2/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bingyangwen/anaconda2/envs/tensorflow/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bingyangwen/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bingyangwen/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bingyangwen/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/bingyangwen/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/bingyangwen/anaconda2/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder.fit(dataset, dataset, epochs=500, batch_size=256, shuffle=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ca9bad0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-860385deb5e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdecoded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder' is not defined"
     ]
    }
   ],
   "source": [
    "encoded_data = encoder.predict(dataset)\n",
    "decoded_data = decoder.predict(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(3):# display original\n",
    "    ax = plt.subplot(2, 3, i + 1)\n",
    "    plt.hist(dataset[i])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, 3, i + 1 + 3)\n",
    "    plt.hist(decoded_imgs[i])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
